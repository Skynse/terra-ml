{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np # for numerical operations and linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "image_dir = \"C:/Users/austi/Downloads/datasetImages_warp256/\"\n",
    "label_csv_path = \"C:/Users/austi/Downloads/\"\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toPILImage = lambda x: tf.keras.preprocessing.image.array_to_img(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AADB(tf.keras.utils.Sequence):\n",
    "    attributes = [\n",
    "        \"balancing_elements\",\n",
    "        \"color_harmony\",\n",
    "        \"content\",\n",
    "        \"depth_of_field\",\n",
    "        \"light\",\n",
    "        \"motion_blur\",\n",
    "        \"object\",\n",
    "        \"repetition\",\n",
    "        \"rule_of_thirds\",\n",
    "        \"symmetry\",\n",
    "        \"vivid_color\",\n",
    "        \"score\",\n",
    "    ]\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        image = tf.image.resize(image, [256, 256])\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        return image\n",
    "\n",
    "    def __init__(self, image_dir, label_csv_path, batch_size=32, test=False):\n",
    "        self.label_csv_path = label_csv_path\n",
    "        self.image_dir = image_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.test = test\n",
    "\n",
    "\n",
    "        self.files, self.labels = self.load_data(self.image_dir, self.label_csv_path, self.test)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.files[index]).convert('RGB')\n",
    "        image = self.preprocess_image(image)\n",
    "        assert image.shape == (256, 256, 3)\n",
    "        label = tf.convert_to_tensor(self.labels[index], dtype=tf.float32)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "    def load_data(self, image_dir, csv_path, test=False):\n",
    "        csv_file = csv_path + 'Dataset.csv' if not test else csv_path + 'Dataset_test.csv'\n",
    "        label_csv = pd.read_csv(csv_file, delimiter=\",\")\n",
    "        files = [os.path.join(image_dir, f) for f in label_csv['ImageFile']]\n",
    "        #labels = label_csv.drop(['ImageFile'], axis=1).values\n",
    "        labels = []\n",
    "        for index, label in label_csv.drop(['ImageFile'], axis=1).iterrows():  # this is for moving score to the last value\n",
    "            label = list(label.values)\n",
    "            label.append(label.pop(9))\n",
    "            labels.append(label)\n",
    "\n",
    "        # Moving 'score' to the last column\n",
    "        labels = np.asarray(labels)\n",
    "        return files, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aadb = AADB(image_dir, label_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(img, label):\n",
    "    print(label)\n",
    "    plt.imshow(toPILImage(img))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dataset):\n",
    "    for images, labels in dataset.take(1):\n",
    "        fig, ax = plt.subplots(figsize=(12, 12))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        images = tf.concat(tf.unstack(images, axis=0), axis=1)  # Concatenate images horizontally\n",
    "        ax.imshow(images)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_example(*aadb[0])\n",
    "len(aadb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#train_ds, val_ds = random_split(aadb, [train_size, val_size])\n",
    "#train_ds, val_ds = tf.data.Dataset.from_tensor_slices(aadb.files[:train_size]), tf.data.Dataset.from_tensor_slices(aadb.files[train_size:])\n",
    "val_size = 500\n",
    "train_size = len(aadb.files) - val_size\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: aadb,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=((256, 256, 3), (12,))\n",
    ").take(train_size)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: aadb,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=((256, 256, 3), (12,))\n",
    ").skip(train_size)\n",
    "\n",
    "train_ds = train_ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_ds = val_ds.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "show_batch(train_ds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankLoss(tf.keras.losses.Loss):\n",
    "\n",
    "    def __init__(self, margin):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Calculate target\n",
    "        target = tf.ones_like(y_true[0], dtype=y_pred[0].dtype)\n",
    "\n",
    "        # Set indices where y_true1 < y_true2 to -1\n",
    "        target = tf.where(y_true[0] < y_true[1], -1.0 * tf.ones_like(target), target)\n",
    "\n",
    "        # Calculate margin ranking loss\n",
    "        loss = tf.maximum(0.0, self.margin - (y_pred[0] - y_pred[1]) * target)\n",
    "        return tf.reduce_mean(loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RegRankLoss(tf.keras.losses.Loss):\n",
    "\n",
    "    def __init__(self, margin: float):\n",
    "        super().__init__()\n",
    "        self.reg_loss = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)\n",
    "        self.rank_loss = RankLoss(margin)\n",
    "\n",
    "    def __call__(self,\n",
    "        y_pred: Tuple[tf.Tensor, tf.Tensor],\n",
    "        y_true: Tuple[tf.Tensor, tf.Tensor]) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "        \n",
    "        loss_reg = (\n",
    "            self.reg_loss(y_pred[0], y_true[0]) +\n",
    "            self.reg_loss(y_pred[1], y_true[1])\n",
    "        ) / 2.0\n",
    "\n",
    "        loss_rank = self.rank_loss(y_pred, y_true)\n",
    "        loss = loss_reg + loss_rank\n",
    "        return loss, loss_reg, loss_rank\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def create_backbone(backbone_name, pretrained=True):\n",
    "    \"\"\"\n",
    "    Creates a backbone model from a pre-trained model.\n",
    "    Args:\n",
    "        backbone_name (str): Name of the backbone model (e.g., 'resnet50').\n",
    "        pretrained (bool): Whether to use pre-trained weights.\n",
    "    Returns:\n",
    "        tf.keras.Model: The backbone model.\n",
    "    \"\"\"\n",
    "    backbone = getattr(tf.keras.applications, backbone_name)(\n",
    "        include_top=False,\n",
    "        weights='imagenet' if pretrained else None,\n",
    "        input_shape=(256, 256, 3)  # Replace with your input shape\n",
    "    )\n",
    "    backbone.trainable = False  # Freeze the backbone layers\n",
    "    return backbone\n",
    "\n",
    "    \n",
    "def create_regression_network(backbone, num_attributes):\n",
    "    \"\"\"\n",
    "    Creates a regression network using the given backbone.\n",
    "    Args:\n",
    "        backbone (tf.keras.Model): The backbone model.\n",
    "        num_attributes (int): Number of attributes for the regression task.\n",
    "    Returns:\n",
    "        tf.keras.Model: The regression network.\n",
    "    \"\"\"\n",
    "    inputs = backbone.input\n",
    "    x = backbone.output\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = tf.keras.layers.Dense(num_attributes, activation='linear')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model = RegressionNetwork(backbone='ResNet50', num_attributes=len(attributes), pretrained=False)\n",
    "model = create_regression_network(create_backbone('MobileNetV2', pretrained=False), 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = RegRankLoss(margin=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001, momentum=0.9)\n",
    "checkpoint_dir = './checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\n",
    "manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=3)\n",
    "\n",
    "train_losses = []\n",
    "train_losses_reg = []\n",
    "train_losses_rank = []\n",
    "val_losses = []\n",
    "num_batches = train_size // (batch_size * 2)  # Calculate the number of batches\n",
    "pbar = tqdm(enumerate(train_ds), total=num_batches)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    for batch, (x, y) in pbar:\n",
    "        with tf.GradientTape() as tape:\n",
    "            x1, x2 = tf.split(x, 2, axis=0)\n",
    "            y1, y2 = tf.split(y, 2, axis=0)\n",
    "            y_pred1 = model(x1, training=True)\n",
    "            y_pred2 = model(x2, training=True)\n",
    "\n",
    "            loss, loss_reg, loss_rank = loss_fn(y_pred=(y_pred1, y_pred2), y_true=(y1, y2))\n",
    "           \n",
    "            pbar.set_description(\"Epoch {}, Reg Loss: {:.4f}, Rank Loss: {:.4f} \".format(epoch, float(loss_reg), float(loss_rank)))\n",
    "\n",
    "        train_losses.append(loss.numpy())\n",
    "        train_losses_reg.append(loss_reg.numpy())\n",
    "        train_losses_rank.append(loss_rank.numpy())\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        train_losses.append(loss.numpy())\n",
    "        train_losses_reg.append(loss_reg.numpy())\n",
    "        train_losses_rank.append(loss_rank.numpy())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(enumerate(val_ds), total=val_size // batch_size)\n",
    "for batch, (x, y) in pbar:\n",
    "    y_pred = model(x, training=False)\n",
    "    loss, _, _ = loss_fn(y_pred, y)\n",
    "    val_losses.append(loss.numpy())\n",
    "    pbar.set_description(f'Val Loss: {np.mean(val_losses):.4f}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\n",
    "    \"balancing_elements\",\n",
    "    \"color_harmony\",\n",
    "    \"content\",\n",
    "    \"depth_of_field\",\n",
    "    \"light\",\n",
    "    \"motion_blur\",\n",
    "    \"object\",\n",
    "    \"repetition\",\n",
    "    \"rule_of_thirds\",\n",
    "    \"symmetry\",\n",
    "    \"vivid_color\",\n",
    "    \"score\",\n",
    "]\n",
    "\n",
    "def show_predictions(dataset, num_samples=3):\n",
    "    for images, labels in dataset.take(1):\n",
    "        predictions = model(images, training=False)\n",
    "        for i in range(num_samples):\n",
    "            image = toPILImage(images[i])\n",
    "            label = {attribute: value for attribute, value in zip(attributes, labels[i].numpy())}\n",
    "            prediction = {attribute: value for attribute, value in zip(attributes, predictions[i].numpy())}\n",
    "            print(f'Label: {label}')\n",
    "            print(f'Prediction: {prediction}')\n",
    "            plt.imshow(image)\n",
    "            plt.show()\n",
    "\n",
    "show_predictions(val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction_custom(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = aadb.preprocess_image(image)\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    prediction = model(image, training=False).numpy()[0]\n",
    "    prediction = {attribute: value for attribute, value in zip(attributes, prediction)}\n",
    "    plt.imshow(toPILImage(image[0]))\n",
    "    plt.show()\n",
    "    print(f'Prediction: {prediction}')\n",
    "\n",
    "show_prediction_custom('C:/Users/austi/Downloads/nice.jpg')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
